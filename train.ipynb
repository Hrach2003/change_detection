{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from torch.nn import functional as F\n",
    "import utils.transforms as trans\n",
    "import utils.utils as util\n",
    "import layer.loss as ls\n",
    "import utils.metric as mc\n",
    "import shutil\n",
    "import cv2\n",
    "\n",
    "import cfg.BCDD as cfg\n",
    "import dataset.rs as dates\n",
    "import time\n",
    "import datetime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "resume = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def check_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def untransform(transform_img, mean_vector):\n",
    "  \n",
    "    transform_img = transform_img.transpose(1, 2, 0)\n",
    "    transform_img += mean_vector\n",
    "    transform_img = transform_img.astype(np.uint8)\n",
    "    transform_img = transform_img[:, :, ::-1]\n",
    "    return transform_img"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\n",
    "def various_distance(out_vec_t0, out_vec_t1, dist_flag):\n",
    "    if dist_flag == 'l2':\n",
    "        distance = F.pairwise_distance(out_vec_t0, out_vec_t1, p=2)\n",
    "    if dist_flag == 'l1':\n",
    "        distance = F.pairwise_distance(out_vec_t0, out_vec_t1, p=1)\n",
    "    if dist_flag == 'cos':\n",
    "        distance = 1 - F.cosine_similarity(out_vec_t0, out_vec_t1)\n",
    "    return distance\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\n",
    "def single_layer_similar_heatmap_visual(output_t0, output_t1, save_change_map_dir, epoch, filename, layer_flag, dist_flag):\n",
    "\n",
    "    # interp = nn.functional.interpolate(size=[cfg.TRANSFROM_SCALES[1],cfg.TRANSFROM_SCALES[0]], mode='bilinear')\n",
    "    n, c, h, w = output_t0.data.shape\n",
    "    out_t0_rz = torch.transpose(output_t0.view(c, h * w), 1, 0)\n",
    "    out_t1_rz = torch.transpose(output_t1.view(c, h * w), 1, 0)\n",
    "    distance = various_distance(out_t0_rz, out_t1_rz, dist_flag=dist_flag)\n",
    "    similar_distance_map = distance.view(h, w).data.cpu().numpy()\n",
    "    similar_distance_map_rz = nn.functional.interpolate(torch.from_numpy(similar_distance_map[np.newaxis, np.newaxis, :]), size=[\n",
    "                                                        cfg.TRANSFROM_SCALES[1], cfg.TRANSFROM_SCALES[0]], mode='bilinear', align_corners=True)\n",
    "    similar_dis_map_colorize = cv2.applyColorMap(np.uint8(\n",
    "        255 * similar_distance_map_rz.data.cpu().numpy()[0][0]), cv2.COLORMAP_JET)\n",
    "    save_change_map_dir_ = os.path.join(\n",
    "        save_change_map_dir, 'epoch_' + str(epoch))\n",
    "    check_dir(save_change_map_dir_)\n",
    "    save_change_map_dir_layer = os.path.join(save_change_map_dir_, layer_flag)\n",
    "    check_dir(save_change_map_dir_layer)\n",
    "    save_weight_fig_dir = os.path.join(\n",
    "        save_change_map_dir_layer, filename + '.jpg')\n",
    "    cv2.imwrite(save_weight_fig_dir, similar_dis_map_colorize)\n",
    "    return similar_distance_map_rz.data.cpu().numpy()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def validate(net, val_dataloader, epoch, save_change_map_dir, save_roc_dir):\n",
    "  \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        cont_conv5_total, cont_fc_total, cont_embedding_total, num = 0.0, 0.0, 0.0, 0.0\n",
    "        metric_for_conditions = util.init_metric_for_class_for_cmu(1)\n",
    "        for batch_idx, batch in enumerate(val_dataloader):\n",
    "            inputs1, input2, targets, filename, height, width = batch\n",
    "            height, width, filename = height.numpy()[0], width.numpy()[\n",
    "                0], filename[0]\n",
    "            inputs1, input2, targets = inputs1.cuda(), input2.cuda(), targets.cuda()\n",
    "            out_conv5, out_fc, out_embedding = net(inputs1, input2)\n",
    "            out_conv5_t0, out_conv5_t1 = out_conv5\n",
    "            out_fc_t0, out_fc_t1 = out_fc\n",
    "            out_embedding_t0, out_embedding_t1 = out_embedding\n",
    "            conv5_distance_map = single_layer_similar_heatmap_visual(\n",
    "                out_conv5_t0, out_conv5_t1, save_change_map_dir, epoch, filename, 'conv5', 'l2')\n",
    "            fc_distance_map = single_layer_similar_heatmap_visual(\n",
    "                out_fc_t0, out_fc_t1, save_change_map_dir, epoch, filename, 'fc', 'l2')\n",
    "            embedding_distance_map = single_layer_similar_heatmap_visual(\n",
    "                out_embedding_t0, out_embedding_t1, save_change_map_dir, epoch, filename, 'embedding', 'l2')\n",
    "            cont_conv5 = mc.RMS_Contrast(conv5_distance_map)\n",
    "            cont_fc = mc.RMS_Contrast(fc_distance_map)\n",
    "            cont_embedding = mc.RMS_Contrast(embedding_distance_map)\n",
    "            cont_conv5_total += cont_conv5\n",
    "            cont_fc_total += cont_fc\n",
    "            cont_embedding_total += cont_embedding\n",
    "            num += 1\n",
    "            prob_change = embedding_distance_map[0][0]\n",
    "            gt = targets.data.cpu().numpy()\n",
    "            FN, FP, posNum, negNum = mc.eval_image_rewrite(\n",
    "                gt[0], prob_change, cl_index=1)\n",
    "            metric_for_conditions[0]['total_fp'] += FP\n",
    "            metric_for_conditions[0]['total_fn'] += FN\n",
    "            metric_for_conditions[0]['total_posnum'] += posNum\n",
    "            metric_for_conditions[0]['total_negnum'] += negNum\n",
    "            cont_conv5_mean, cont_fc_mean, cont_embedding_mean = cont_conv5_total/num, \\\n",
    "                cont_fc_total/num, cont_embedding_total/num\n",
    "\n",
    "        thresh = np.array(range(0, 256)) / 255.0\n",
    "        conds = metric_for_conditions.keys()\n",
    "        for cond_name in conds:\n",
    "            total_posnum = metric_for_conditions[cond_name]['total_posnum']\n",
    "            total_negnum = metric_for_conditions[cond_name]['total_negnum']\n",
    "            total_fn = metric_for_conditions[cond_name]['total_fn']\n",
    "            total_fp = metric_for_conditions[cond_name]['total_fp']\n",
    "            metric_dict = mc.pxEval_maximizeFMeasure(total_posnum, total_negnum,\n",
    "                                                     total_fn, total_fp, thresh=thresh)\n",
    "            metric_for_conditions[cond_name].setdefault('metric', metric_dict)\n",
    "            metric_for_conditions[cond_name].setdefault(\n",
    "                'contrast_conv5', cont_conv5_mean)\n",
    "            metric_for_conditions[cond_name].setdefault(\n",
    "                'contrast_fc', cont_fc_mean)\n",
    "            metric_for_conditions[cond_name].setdefault(\n",
    "                'contrast_embedding', cont_embedding_mean)\n",
    "\n",
    "        f_score_total = 0.0\n",
    "        for cond_name in conds:\n",
    "            pr, recall, f_score = metric_for_conditions[cond_name]['metric']['precision'], metric_for_conditions[\n",
    "                cond_name]['metric']['recall'], metric_for_conditions[cond_name]['metric']['MaxF']\n",
    "            roc_save_epoch_dir = os.path.join(save_roc_dir, str(epoch))\n",
    "            check_dir(roc_save_epoch_dir)\n",
    "            roc_save_epoch_cat_dir = os.path.join(roc_save_epoch_dir)\n",
    "            check_dir(roc_save_epoch_cat_dir)\n",
    "            mc.save_PTZ_metric2disk(\n",
    "                metric_for_conditions[cond_name], roc_save_epoch_cat_dir)\n",
    "            roc_save_dir = os.path.join(roc_save_epoch_cat_dir,\n",
    "                                        '_' + str(cond_name) + '_roc.png')\n",
    "            mc.plotPrecisionRecall(pr, recall, roc_save_dir, benchmark_pr=None)\n",
    "            f_score_total += f_score\n",
    "\n",
    "        print(f_score_total/(len(conds)))\n",
    "        return f_score_total/len(conds)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def main():\n",
    "  \n",
    "    #########  configs ###########\n",
    "    best_metric = 0\n",
    "    ######  load datasets ########\n",
    "    train_transform_det = trans.Compose([\n",
    "        trans.Scale(cfg.TRANSFROM_SCALES),\n",
    "    ])\n",
    "    val_transform_det = trans.Compose([\n",
    "        trans.Scale(cfg.TRANSFROM_SCALES),\n",
    "    ])\n",
    "    train_data = dates.Dataset(cfg.TRAIN_DATA_PATH, cfg.TRAIN_LABEL_PATH,\n",
    "                               cfg.TRAIN_TXT_PATH, 'train', transform=True,\n",
    "                               transform_med=train_transform_det)\n",
    "    train_loader = Data.DataLoader(train_data, batch_size=128,\n",
    "                                   shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_data = dates.Dataset(cfg.VAL_DATA_PATH, cfg.VAL_LABEL_PATH,\n",
    "                             cfg.VAL_TXT_PATH, 'val', transform=True,\n",
    "                             transform_med=val_transform_det)\n",
    "    val_loader = Data.DataLoader(val_data, batch_size=cfg.BATCH_SIZE,\n",
    "                                 shuffle=False, num_workers=4, pin_memory=True)\n",
    "    ######  build  models ########\n",
    "    base_seg_model = 'resnet50'\n",
    "    if base_seg_model == 'vgg':\n",
    "        import model.siameseNet.d_aa as models\n",
    "        pretrain_deeplab_path = os.path.join(\n",
    "            cfg.PRETRAIN_MODEL_PATH, 'vgg16.pth')\n",
    "        model = models.SiameseNet(norm_flag='l2')\n",
    "        if resume:\n",
    "            checkpoint = torch.load(cfg.TRAINED_BEST_PERFORMANCE_CKPT)\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print('resume success')\n",
    "        else:\n",
    "            deeplab_pretrain_model = torch.load(pretrain_deeplab_path)\n",
    "            model.init_parameters_from_deeplab(deeplab_pretrain_model)\n",
    "            print('load vgg')\n",
    "    else:\n",
    "        import model.siameseNet.dares as models\n",
    "        model = models.SiameseNet(norm_flag='l2')\n",
    "        if resume:\n",
    "            checkpoint = torch.load(cfg.TRAINED_BEST_PERFORMANCE_CKPT)\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            print('resume success')\n",
    "        else:\n",
    "            print('load resnet50')\n",
    "\n",
    "    model = model.cuda()\n",
    "    MaskLoss = ls.ContrastiveLoss1()\n",
    "    ab_test_dir = os.path.join(cfg.SAVE_PRED_PATH, 'contrastive_loss')\n",
    "    check_dir(ab_test_dir)\n",
    "    save_change_map_dir = os.path.join(ab_test_dir, 'changemaps/')\n",
    "    save_valid_dir = os.path.join(ab_test_dir, 'valid_imgs')\n",
    "    save_roc_dir = os.path.join(ab_test_dir, 'roc')\n",
    "    check_dir(save_change_map_dir), check_dir(\n",
    "        save_valid_dir), check_dir(save_roc_dir)\n",
    "    #########\n",
    "    ######### optimizer ##########\n",
    "    ######## how to set different learning rate for differernt layers #########\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(\n",
    "    ), lr=cfg.INIT_LEARNING_RATE, weight_decay=cfg.DECAY)\n",
    "    ######## iter img_label pairs ###########\n",
    "    loss_total = 0\n",
    "    time_start = time.time()\n",
    "    for epoch in range(60):\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            step = epoch * len(train_loader) + batch_idx\n",
    "            util.adjust_learning_rate(cfg.INIT_LEARNING_RATE, optimizer, step)\n",
    "            model.train()\n",
    "            img1_idx, img2_idx, label_idx, filename, height, width = batch\n",
    "            img1, img2, label = img1_idx.cuda(), img2_idx.cuda(), label_idx.cuda()\n",
    "            label = label.float()\n",
    "            out_conv5, out_fc, out_embedding = model(img1, img2)\n",
    "            out_conv5_t0, out_conv5_t1 = out_conv5\n",
    "            out_fc_t0, out_fc_t1 = out_fc\n",
    "            out_embedding_t0, out_embedding_t1 = out_embedding\n",
    "            label_rz_conv5 = util.rz_label(\n",
    "                label, size=out_conv5_t0.data.cpu().numpy().shape[2:]).cuda()\n",
    "            label_rz_fc = util.rz_label(\n",
    "                label, size=out_fc_t0.data.cpu().numpy().shape[2:]).cuda()\n",
    "            label_rz_embedding = util.rz_label(\n",
    "                label, size=out_embedding_t0.data.cpu().numpy().shape[2:]).cuda()\n",
    "            contractive_loss_conv5 = MaskLoss(\n",
    "                out_conv5_t0, out_conv5_t1, label_rz_conv5)\n",
    "            contractive_loss_fc = MaskLoss(out_fc_t0, out_fc_t1, label_rz_fc)\n",
    "            contractive_loss_embedding = MaskLoss(\n",
    "                out_embedding_t0, out_embedding_t1, label_rz_embedding)\n",
    "            loss = contractive_loss_conv5 + contractive_loss_fc + contractive_loss_embedding\n",
    "            loss_total += loss.data.cpu()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (batch_idx) % 20 == 0:\n",
    "                print(\"Epoch [%d/%d] Loss: %.4f Mask_Loss_conv5: %.4f Mask_Loss_fc: %.4f \"\n",
    "                      \"Mask_Loss_embedding: %.4f\" % (epoch, batch_idx, loss.item(), contractive_loss_conv5.item(),\n",
    "                                                     contractive_loss_fc.item(), contractive_loss_embedding.item()))\n",
    "            if (batch_idx) % 1000 == 0:\n",
    "                model.eval()\n",
    "                current_metric = validate(\n",
    "                    model, val_loader, epoch, save_change_map_dir, save_roc_dir)\n",
    "                if current_metric > best_metric:\n",
    "                    torch.save({'state_dict': model.state_dict()},\n",
    "                               os.path.join(ab_test_dir, 'model' + str(epoch) + '.pth'))\n",
    "                    shutil.copy(os.path.join(ab_test_dir, 'model' + str(epoch) + '.pth'),\n",
    "                                os.path.join(ab_test_dir, 'model_best.pth'))\n",
    "                    best_metric = current_metric\n",
    "        current_metric = validate(\n",
    "            model, val_loader, epoch, save_change_map_dir, save_roc_dir)\n",
    "        if current_metric > best_metric:\n",
    "            torch.save({'state_dict': model.state_dict()},\n",
    "                       os.path.join(ab_test_dir, 'model' + str(epoch) + '.pth'))\n",
    "            shutil.copy(os.path.join(ab_test_dir, 'model' + str(epoch) + '.pth'),\n",
    "                        os.path.join(ab_test_dir, 'model_best.pth'))\n",
    "            best_metric = current_metric\n",
    "        if epoch % 5 == 0:\n",
    "            torch.save({'state_dict': model.state_dict()},\n",
    "                       os.path.join(ab_test_dir, 'model' + str(epoch) + '.pth'))\n",
    "    elapsed = round(time.time() - time_start)\n",
    "    elapsed = str(datetime.timedelta(seconds=elapsed))\n",
    "    print('Elapsed {}'.format(elapsed))\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "main()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}